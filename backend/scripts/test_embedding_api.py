# backend/scripts/test_embedding_api.py
import asyncio
import os
import sys
from dotenv import load_dotenv
import time
from typing import List

# ç¡®ä¿å¯ä»¥ä»è„šæœ¬ç›®å½•å¯¼å…¥ app æœåŠ¡
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

# åŠ è½½ .env æ–‡ä»¶
load_dotenv(os.path.join(project_root, '.env'))

# å¯¼å…¥ llm_service (ç¡®ä¿åœ¨ load_dotenv ä¹‹å)
try:
    from app.services.llm_service import llm_service
except ImportError as e:
    print(f"å¯¼å…¥ llm_service å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ä½ åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ backend/ æ–‡ä»¶å¤¹ä¸‹è¿è¡Œæ­¤è„šæœ¬ï¼Œæˆ–è€…è·¯å¾„è®¾ç½®æ­£ç¡®ã€‚")
    sys.exit(1)

# --- æµ‹è¯•é…ç½® ---
# åˆ›å»ºä¸€äº›ç®€å•çš„æµ‹è¯•æ–‡æœ¬
TEST_TEXTS = [f"This is test sentence number {i+1} for embedding." for i in range(55)] # åˆ›å»º 55 ä¸ªæ–‡æœ¬ï¼Œæ–¹ä¾¿æµ‹è¯•ä¸åŒæ‰¹æ¬¡
MODEL_TO_TEST = os.getenv("EMBEDDING_MODEL", "text-embedding-v3") # ä» env è·å–æ¨¡å‹

async def test_batch_embedding(texts_to_embed: List[str], batch_size: int):
    """
    æµ‹è¯•ä»¥æŒ‡å®šçš„æ‰¹é‡å¤§å°è°ƒç”¨åµŒå…¥ APIã€‚

    Args:
        texts_to_embed: è¦åµŒå…¥çš„æ–‡æœ¬åˆ—è¡¨ã€‚
        batch_size: æ¯ä¸ª API è¯·æ±‚å‘é€çš„æ–‡æœ¬æ•°é‡ã€‚
    """
    print(f"\n--- æµ‹è¯• Batch Size: {batch_size} ---")
    all_embeddings = []
    total_texts = len(texts_to_embed)
    batches_processed = 0
    start_overall = time.time()

    for i in range(0, total_texts, batch_size):
        batch = texts_to_embed[i : i + batch_size]
        batches_processed += 1
        print(f"  å‘é€ç¬¬ {batches_processed} æ‰¹ï¼Œæ•°é‡: {len(batch)} (æ–‡æœ¬ {i+1} åˆ° {min(i + batch_size, total_texts)})")
        start_batch = time.time()

        # è°ƒç”¨ get_embeddings
        batch_embeddings = await llm_service.get_embeddings(
            texts=batch,
            model=MODEL_TO_TEST
            # dimensions å‚æ•°ä¸ä¼ é€’ï¼Œä½¿ç”¨æ¨¡å‹é»˜è®¤å€¼
        )

        end_batch = time.time()
        duration_batch = end_batch - start_batch

        if batch_embeddings is not None:
            print(f"  âœ… æˆåŠŸè·å– {len(batch_embeddings)} ä¸ªåµŒå…¥å‘é‡ã€‚è€—æ—¶: {duration_batch:.2f} ç§’.")
            all_embeddings.extend(batch_embeddings)
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä¸€ä¸ªå°çš„å»¶è¿Ÿï¼Œé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
            await asyncio.sleep(0.5) # æš‚åœ 0.5 ç§’
        else:
            print(f"  âŒ å¤±è´¥ï¼šæœªèƒ½è·å–è¯¥æ‰¹æ¬¡çš„åµŒå…¥å‘é‡ã€‚")
            # å¯ä»¥é€‰æ‹©åœ¨è¿™é‡Œåœæ­¢æµ‹è¯•æˆ–ç»§ç»­æµ‹è¯•å…¶ä»–æ‰¹æ¬¡
            # return False # å¦‚æœå¸Œæœ›å¤±è´¥æ—¶åœæ­¢æ•´ä¸ªæµ‹è¯•

    end_overall = time.time()
    duration_overall = end_overall - start_overall
    print(f"--- æµ‹è¯• Batch Size {batch_size} å®Œæˆ ---")
    print(f"æ€»è®¡ {batches_processed} æ‰¹ï¼ŒæˆåŠŸè·å– {len(all_embeddings)} / {total_texts} ä¸ªåµŒå…¥å‘é‡ã€‚")
    print(f"æ€»è€—æ—¶: {duration_overall:.2f} ç§’.")
    return len(all_embeddings) == total_texts

async def main():
    if not llm_service or not llm_service.client:
        print("LLM æœåŠ¡æœªæˆåŠŸåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ API Key å’Œ .env æ–‡ä»¶ã€‚")
        return

    print(f"å¼€å§‹æµ‹è¯•é€šä¹‰åƒé—®åµŒå…¥ API ({MODEL_TO_TEST}) è°ƒç”¨...")
    print(f"å°†ä½¿ç”¨ {len(TEST_TEXTS)} ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚")

    # æµ‹è¯•ä¸åŒçš„æ‰¹é‡å¤§å°
    batch_sizes_to_test = [50, 25, 16, 10, 5, 1]

    successful_batch_size = None
    for size in batch_sizes_to_test:
        success = await test_batch_embedding(TEST_TEXTS, size)
        if success:
            successful_batch_size = size
            print(f"\nğŸ‰ æ‰¹é‡å¤§å° {size} æµ‹è¯•æˆåŠŸï¼")
            # å¯ä»¥é€‰æ‹©æ‰¾åˆ°ç¬¬ä¸€ä¸ªæˆåŠŸçš„å°±åœæ­¢
            # break
        else:
            print(f"\nâš ï¸ æ‰¹é‡å¤§å° {size} æµ‹è¯•å¤±è´¥ã€‚")

    if successful_batch_size:
        print(f"\nç»“è®ºï¼šAPI ä¼¼ä¹æ”¯æŒè‡³å°‘ {successful_batch_size} çš„æ‰¹é‡å¤§å°ã€‚")
        print("å»ºè®®åœ¨ vector_search_service.py ä¸­ä½¿ç”¨è¿™ä¸ªæˆ–æ›´å°çš„æ‰¹é‡å¤§å°ã€‚")
    else:
        print("\nç»“è®ºï¼šæ‰€æœ‰æµ‹è¯•çš„æ‰¹é‡å¤§å°éƒ½å¤±è´¥äº†ã€‚è¯·æ£€æŸ¥ï¼š")
        print("1. API Key æ˜¯å¦æœ‰æ•ˆä¸”æœ‰è¶³å¤Ÿé¢åº¦ã€‚")
        print("2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ã€‚")
        print(f"3. æ¨¡å‹åç§° '{MODEL_TO_TEST}' æ˜¯å¦æ­£ç¡®ä¸”è¢« API ç«¯ç‚¹æ”¯æŒã€‚")
        print("4. æŸ¥çœ‹æ›´è¯¦ç»†çš„æ—¥å¿—è¾“å‡ºä»¥è·å–çº¿ç´¢ã€‚")

if __name__ == "__main__":
    asyncio.run(main())